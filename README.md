This is a python-tensorflow implementation of Neural Style Transfer, described in detail by [Gatys et al. 2015](http://arxiv.org/abs/1508.06576). This work wouldn't have been possible without knowledge obtained from the "[Convolutional Neural Networks](https://www.coursera.org/learn/convolutional-neural-networks)" course, offered by [deeplearning.ai](http://www.deeplearning.ai). It is worth mentioning that they, in turn, took inspiration from [Harish Nayaranan](https://harishnarayanan.org/writing/artistic-style-transfer)'s and [log0](https://github.com/log0/neural-style-painting)'s work.

This repo has two different implementations of neural style transfer. One meant for combining a pair of images ([nst.py](nst.py)), and the another one to combine a style image with all the frames of a video ([nst_video.py](nst_video.py)). These codes use transfer learning from the vgg-19 model to process the images, which you can download [here](http://www.vlfeat.org/matconvnet/models/imagenet-vgg-verydeep-19.mat).
